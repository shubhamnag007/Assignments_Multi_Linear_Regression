{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17ac48bc",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1b1e1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: <object object at 0x000001D4176B2BD0>\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as mn\n",
    "import scipy.stats as stat\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.graphics.regressionplots import influence_plot\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b20dfb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Model</th>\n",
       "      <th>Price</th>\n",
       "      <th>Age_08_04</th>\n",
       "      <th>Mfg_Month</th>\n",
       "      <th>Mfg_Year</th>\n",
       "      <th>KM</th>\n",
       "      <th>Fuel_Type</th>\n",
       "      <th>HP</th>\n",
       "      <th>Met_Color</th>\n",
       "      <th>...</th>\n",
       "      <th>Central_Lock</th>\n",
       "      <th>Powered_Windows</th>\n",
       "      <th>Power_Steering</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Mistlamps</th>\n",
       "      <th>Sport_Model</th>\n",
       "      <th>Backseat_Divider</th>\n",
       "      <th>Metallic_Rim</th>\n",
       "      <th>Radio_cassette</th>\n",
       "      <th>Tow_Bar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors</td>\n",
       "      <td>13500</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>2002</td>\n",
       "      <td>46986</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors</td>\n",
       "      <td>13750</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>2002</td>\n",
       "      <td>72937</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors</td>\n",
       "      <td>13950</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>2002</td>\n",
       "      <td>41711</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors</td>\n",
       "      <td>14950</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>2002</td>\n",
       "      <td>48000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>TOYOTA Corolla 2.0 D4D HATCHB SOL 2/3-Doors</td>\n",
       "      <td>13750</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>2002</td>\n",
       "      <td>38500</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                           Model  Price  Age_08_04  \\\n",
       "0   1   TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors  13500         23   \n",
       "1   2   TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors  13750         23   \n",
       "2   3   TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors  13950         24   \n",
       "3   4   TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors  14950         26   \n",
       "4   5     TOYOTA Corolla 2.0 D4D HATCHB SOL 2/3-Doors  13750         30   \n",
       "\n",
       "   Mfg_Month  Mfg_Year     KM Fuel_Type  HP  Met_Color  ... Central_Lock  \\\n",
       "0         10      2002  46986    Diesel  90          1  ...            1   \n",
       "1         10      2002  72937    Diesel  90          1  ...            1   \n",
       "2          9      2002  41711    Diesel  90          1  ...            0   \n",
       "3          7      2002  48000    Diesel  90          0  ...            0   \n",
       "4          3      2002  38500    Diesel  90          0  ...            1   \n",
       "\n",
       "   Powered_Windows  Power_Steering  Radio  Mistlamps  Sport_Model  \\\n",
       "0                1               1      0          0            0   \n",
       "1                0               1      0          0            0   \n",
       "2                0               1      0          0            0   \n",
       "3                0               1      0          0            0   \n",
       "4                1               1      0          1            0   \n",
       "\n",
       "   Backseat_Divider  Metallic_Rim  Radio_cassette  Tow_Bar  \n",
       "0                 1             0               0        0  \n",
       "1                 1             0               0        0  \n",
       "2                 1             0               0        0  \n",
       "3                 1             0               0        0  \n",
       "4                 1             0               0        0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing dataset\n",
    "raw_data = pd.read_csv('ToyotaCorolla.csv', encoding= 'latin1')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8ac214e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows(1436, 38)Columns\n"
     ]
    }
   ],
   "source": [
    "print('Number of Rows{}Columns'.format(raw_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f85cb7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Age_08_04</th>\n",
       "      <th>KM</th>\n",
       "      <th>HP</th>\n",
       "      <th>cc</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Gears</th>\n",
       "      <th>Quarterly_Tax</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13500</td>\n",
       "      <td>23</td>\n",
       "      <td>46986</td>\n",
       "      <td>90</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>210</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13750</td>\n",
       "      <td>23</td>\n",
       "      <td>72937</td>\n",
       "      <td>90</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>210</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13950</td>\n",
       "      <td>24</td>\n",
       "      <td>41711</td>\n",
       "      <td>90</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>210</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14950</td>\n",
       "      <td>26</td>\n",
       "      <td>48000</td>\n",
       "      <td>90</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>210</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13750</td>\n",
       "      <td>30</td>\n",
       "      <td>38500</td>\n",
       "      <td>90</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>210</td>\n",
       "      <td>1170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>7500</td>\n",
       "      <td>69</td>\n",
       "      <td>20544</td>\n",
       "      <td>86</td>\n",
       "      <td>1300</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>69</td>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>10845</td>\n",
       "      <td>72</td>\n",
       "      <td>19000</td>\n",
       "      <td>86</td>\n",
       "      <td>1300</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>69</td>\n",
       "      <td>1015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>8500</td>\n",
       "      <td>71</td>\n",
       "      <td>17016</td>\n",
       "      <td>86</td>\n",
       "      <td>1300</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>69</td>\n",
       "      <td>1015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>7250</td>\n",
       "      <td>70</td>\n",
       "      <td>16916</td>\n",
       "      <td>86</td>\n",
       "      <td>1300</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>69</td>\n",
       "      <td>1015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>6950</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>1600</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>1114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1436 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Price  Age_08_04     KM   HP    cc  Doors  Gears  Quarterly_Tax  Weight\n",
       "0     13500         23  46986   90  2000      3      5            210    1165\n",
       "1     13750         23  72937   90  2000      3      5            210    1165\n",
       "2     13950         24  41711   90  2000      3      5            210    1165\n",
       "3     14950         26  48000   90  2000      3      5            210    1165\n",
       "4     13750         30  38500   90  2000      3      5            210    1170\n",
       "...     ...        ...    ...  ...   ...    ...    ...            ...     ...\n",
       "1431   7500         69  20544   86  1300      3      5             69    1025\n",
       "1432  10845         72  19000   86  1300      3      5             69    1015\n",
       "1433   8500         71  17016   86  1300      3      5             69    1015\n",
       "1434   7250         70  16916   86  1300      3      5             69    1015\n",
       "1435   6950         76      1  110  1600      5      5             19    1114\n",
       "\n",
       "[1436 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data=raw_data[[\"Price\",\"Age_08_04\",\"KM\",\"HP\",\"cc\",\"Doors\",\"Gears\",\"Quarterly_Tax\",\"Weight\"]]\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15edd9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Age_08_04</th>\n",
       "      <th>KM</th>\n",
       "      <th>HP</th>\n",
       "      <th>cc</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Gears</th>\n",
       "      <th>Quarterly_Tax</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1436.000000</td>\n",
       "      <td>1436.000000</td>\n",
       "      <td>1436.000000</td>\n",
       "      <td>1436.000000</td>\n",
       "      <td>1436.00000</td>\n",
       "      <td>1436.000000</td>\n",
       "      <td>1436.000000</td>\n",
       "      <td>1436.000000</td>\n",
       "      <td>1436.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10730.824513</td>\n",
       "      <td>55.947075</td>\n",
       "      <td>68533.259749</td>\n",
       "      <td>101.502089</td>\n",
       "      <td>1576.85585</td>\n",
       "      <td>4.033426</td>\n",
       "      <td>5.026462</td>\n",
       "      <td>87.122563</td>\n",
       "      <td>1072.45961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3626.964585</td>\n",
       "      <td>18.599988</td>\n",
       "      <td>37506.448872</td>\n",
       "      <td>14.981080</td>\n",
       "      <td>424.38677</td>\n",
       "      <td>0.952677</td>\n",
       "      <td>0.188510</td>\n",
       "      <td>41.128611</td>\n",
       "      <td>52.64112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4350.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>1300.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8450.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>43000.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>1400.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>1040.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9900.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>63389.500000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>1600.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>1070.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11950.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>87020.750000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>1600.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>1085.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>32500.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>243000.000000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>16000.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>283.000000</td>\n",
       "      <td>1615.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Price    Age_08_04             KM           HP           cc  \\\n",
       "count   1436.000000  1436.000000    1436.000000  1436.000000   1436.00000   \n",
       "mean   10730.824513    55.947075   68533.259749   101.502089   1576.85585   \n",
       "std     3626.964585    18.599988   37506.448872    14.981080    424.38677   \n",
       "min     4350.000000     1.000000       1.000000    69.000000   1300.00000   \n",
       "25%     8450.000000    44.000000   43000.000000    90.000000   1400.00000   \n",
       "50%     9900.000000    61.000000   63389.500000   110.000000   1600.00000   \n",
       "75%    11950.000000    70.000000   87020.750000   110.000000   1600.00000   \n",
       "max    32500.000000    80.000000  243000.000000   192.000000  16000.00000   \n",
       "\n",
       "             Doors        Gears  Quarterly_Tax      Weight  \n",
       "count  1436.000000  1436.000000    1436.000000  1436.00000  \n",
       "mean      4.033426     5.026462      87.122563  1072.45961  \n",
       "std       0.952677     0.188510      41.128611    52.64112  \n",
       "min       2.000000     3.000000      19.000000  1000.00000  \n",
       "25%       3.000000     5.000000      69.000000  1040.00000  \n",
       "50%       4.000000     5.000000      85.000000  1070.00000  \n",
       "75%       5.000000     5.000000      85.000000  1085.00000  \n",
       "max       5.000000     6.000000     283.000000  1615.00000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a623d71",
   "metadata": {},
   "source": [
    "### ^Observation: There are some missing values in the Data set by reading Counts from Above\n",
    "## Checking for Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c44b604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1436 entries, 0 to 1435\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype\n",
      "---  ------         --------------  -----\n",
      " 0   Price          1436 non-null   int64\n",
      " 1   Age_08_04      1436 non-null   int64\n",
      " 2   KM             1436 non-null   int64\n",
      " 3   HP             1436 non-null   int64\n",
      " 4   cc             1436 non-null   int64\n",
      " 5   Doors          1436 non-null   int64\n",
      " 6   Gears          1436 non-null   int64\n",
      " 7   Quarterly_Tax  1436 non-null   int64\n",
      " 8   Weight         1436 non-null   int64\n",
      "dtypes: int64(9)\n",
      "memory usage: 101.1 KB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1c7c9f",
   "metadata": {},
   "source": [
    "### ^Observation: all the data types are correct .\n",
    "## Renaming the columns name and making it short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de175c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Age</th>\n",
       "      <th>KM</th>\n",
       "      <th>HP</th>\n",
       "      <th>CC</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Gears</th>\n",
       "      <th>QT</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13500</td>\n",
       "      <td>23</td>\n",
       "      <td>46986</td>\n",
       "      <td>90</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>210</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13750</td>\n",
       "      <td>23</td>\n",
       "      <td>72937</td>\n",
       "      <td>90</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>210</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13950</td>\n",
       "      <td>24</td>\n",
       "      <td>41711</td>\n",
       "      <td>90</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>210</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14950</td>\n",
       "      <td>26</td>\n",
       "      <td>48000</td>\n",
       "      <td>90</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>210</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13750</td>\n",
       "      <td>30</td>\n",
       "      <td>38500</td>\n",
       "      <td>90</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>210</td>\n",
       "      <td>1170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Price  Age     KM  HP    CC  Doors  Gears   QT  Weight\n",
       "0  13500   23  46986  90  2000      3      5  210    1165\n",
       "1  13750   23  72937  90  2000      3      5  210    1165\n",
       "2  13950   24  41711  90  2000      3      5  210    1165\n",
       "3  14950   26  48000  90  2000      3      5  210    1165\n",
       "4  13750   30  38500  90  2000      3      5  210    1170"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=raw_data.rename({'Age_08_04':'Age','cc':'CC','Quarterly_Tax':'QT'},axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "387e02d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Age</th>\n",
       "      <th>KM</th>\n",
       "      <th>HP</th>\n",
       "      <th>CC</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Gears</th>\n",
       "      <th>QT</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Price, Age, KM, HP, CC, Doors, Gears, QT, Weight]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cHECKING FOR MISSING VALUES\n",
    "data[data.values==0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ed426d",
   "metadata": {},
   "source": [
    "#### ^Observation: Notice there are no '0' values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "440afbaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Price     0\n",
       "Age       0\n",
       "KM        0\n",
       "HP        0\n",
       "CC        0\n",
       "Doors     0\n",
       "Gears     0\n",
       "QT        0\n",
       "Weight    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81f7dc75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VISUALIZING MISSING VALUES\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(data.isnull(),cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8c8d7b",
   "metadata": {},
   "source": [
    "### ^Observation: Feature 'HP' has missing Values in the data set\n",
    "* We will have to handle the missing values by observing the distribution and making the optimal choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5c85038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 90, 192,  69, 110,  97,  71, 116,  98,  86,  72, 107,  73],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.HP.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a93e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data['HP'])\n",
    "plt.title('HP')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41065634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn.matrix(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c3cad5",
   "metadata": {},
   "source": [
    "#### ^Observation: After checking above there is no null value present in the dataset\n",
    "### Checking for Duplicated Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "297c8ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.duplicated()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a841472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Age</th>\n",
       "      <th>KM</th>\n",
       "      <th>HP</th>\n",
       "      <th>CC</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Gears</th>\n",
       "      <th>QT</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>24950</td>\n",
       "      <td>8</td>\n",
       "      <td>13253</td>\n",
       "      <td>116</td>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>234</td>\n",
       "      <td>1320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Age     KM   HP    CC  Doors  Gears   QT  Weight\n",
       "113  24950    8  13253  116  2000      5      5  234    1320"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44987248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Age</th>\n",
       "      <th>KM</th>\n",
       "      <th>HP</th>\n",
       "      <th>CC</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Gears</th>\n",
       "      <th>QT</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Price, Age, KM, HP, CC, Doors, Gears, QT, Weight]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.drop_duplicates().reset_index(drop=True)\n",
    "data[data.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bea5d50",
   "metadata": {},
   "source": [
    "### ^Observation: There are duplicated values in the dataset\n",
    "* Hence, we dropped those values\n",
    "\n",
    "### Let's find how many discrete and continuous feature are their in our dataset by seperating them in variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab62f680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete Variables Count: 5\n"
     ]
    }
   ],
   "source": [
    "discrete_feature=[feature for feature in data.columns if len(data[feature].unique())<20 and feature]\n",
    "print('Discrete Variables Count: {}'.format(len(discrete_feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "daafc966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Feature Count 4\n"
     ]
    }
   ],
   "source": [
    "continuous_feature=[feature for feature in data.columns if data[feature].dtype!='O' and feature not in discrete_feature]\n",
    "print('Continuous Feature Count {}'.format(len(continuous_feature)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19795636",
   "metadata": {},
   "source": [
    "### Exploratory Data Anlaysis\n",
    "\n",
    "### Visualizing the Distribution of Continuous Features with the help of Histograms and Probability Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0ead419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "def plot_data(data,feature):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    data[feature].hist()\n",
    "    plt.subplot(1,2,2)\n",
    "    stat.probplot(data[feature],dist='norm',plot=pylab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5470633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Weight')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_data(data,'Price')\n",
    "plt.title('Price')\n",
    "plot_data(data,'Age')\n",
    "plt.title('Age')\n",
    "plot_data(data,'KM')\n",
    "plt.title('KM')\n",
    "plot_data(data,'Weight')\n",
    "plt.title('Weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5a77fb",
   "metadata": {},
   "source": [
    "### Square root transformation and visualizing the Histogram to determine any possible changes in distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2141d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Weight')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=data.copy()\n",
    "df[continuous_feature]=np.sqrt(df[continuous_feature])\n",
    "\n",
    "plot_data(df,'Price')\n",
    "plt.title('Price')\n",
    "plot_data(df,'Age')\n",
    "plt.title('Age')\n",
    "plot_data(df,'KM')\n",
    "plt.title('KM')\n",
    "plot_data(df,'Weight')\n",
    "plt.title('Weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b66f21",
   "metadata": {},
   "source": [
    "### Cuberoot transformation and visualizing the Histogram to determine any possible changes in distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78dc77a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Weight')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=data.copy()\n",
    "df[continuous_feature]=np.cbrt(df[continuous_feature])\n",
    "\n",
    "plot_data(df,'Price')\n",
    "plt.title('Price')\n",
    "plot_data(df,'Age')\n",
    "plt.title('Age')\n",
    "plot_data(df,'KM')\n",
    "plt.title('KM')\n",
    "plot_data(df,'Weight')\n",
    "plt.title('Weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87925a1",
   "metadata": {},
   "source": [
    "* Note: Most of the Continuous Features visually do not look normally distributed lets have some Hypothetical test to check the normailty.\n",
    "\n",
    "### The Shapiro-Wilk test is a test of normality. It is used to determine whether or not a sample comes from a normal distribution.\n",
    "\n",
    "* To perform a Shapiro-Wilk test in Python we can use the scipy.stats.shapiro() function, which takes on the following syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2527256a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Price', 'Age', 'KM', 'HP', 'CC', 'Doors', 'Gears', 'QT', 'Weight'], dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5db83ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price feature ShapiroResult(statistic=0.8534726500511169, pvalue=1.5959173670279415e-34) \n",
      "Age feature ShapiroResult(statistic=0.9266955256462097, pvalue=6.739428532958423e-26) \n",
      "Weight feature ShapiroResult(statistic=0.7825545072555542, pvalue=5.042992913412152e-40) \n",
      "KM feature ShapiroResult(statistic=0.947583794593811, pvalue=3.4451158696360995e-22)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "#perform Shapiro-Wilk test\n",
    "print('Price feature',shapiro(data.Price),'\\n'\n",
    "     'Age feature',shapiro(data.Age),'\\n'\n",
    "     'Weight feature',shapiro(data.Weight),'\\n'\n",
    "     'KM feature',shapiro(data.KM))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a896bf28",
   "metadata": {},
   "source": [
    "### ^Observation: Since the p-values are less than .05, we reject the null hypothesis.\n",
    "\n",
    "* We have sufficient evidence to say that the sample data does not come from a normal distribution.\n",
    "\n",
    "### Visualizing the Relation between each independent Feature with respect to the Dependent Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0cb22d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in continuous_feature:\n",
    "    if feature!=\"Price\":\n",
    "        df=data.copy()         \n",
    "        plt.scatter(df[feature],df['Price'])\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel('Price')\n",
    "        plt.title(feature)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56307d35",
   "metadata": {},
   "source": [
    "### ^Observation: Age feature has a good linear relation with Price a Negative Correlation as compare to other features\n",
    "\n",
    "### Lets analyze the relationship between the discrete variables and Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edcdc916",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in discrete_feature:\n",
    "    df=data.copy()\n",
    "    df.groupby(feature)[\"Price\"].median().plot.bar()\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d572698b",
   "metadata": {},
   "source": [
    "### ^Observation:There is'nt much of difference between how much Gears and Doors each Car has to have a sginificant amount of changes in Prices from each other and there is'nt any direct relation\n",
    "\n",
    "### Visualizing Continuous Datatype for Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ae716d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.copy() \n",
    "fig, axes=plt.subplots(4,1,figsize=(16,9),sharex=False,sharey=False)\n",
    "sns.boxplot(x='Price',data=df,palette='crest',ax=axes[0])\n",
    "sns.boxplot(x='Age',data=df,palette='crest',ax=axes[1])\n",
    "sns.boxplot(x='KM',data=df,palette='crest',ax=axes[2])\n",
    "sns.boxplot(x='Weight',data=df,palette='crest',ax=axes[3])\n",
    "plt.tight_layout(pad=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "992c8520",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=data.copy()\n",
    "for i in data['Price']:\n",
    "    q1 = np.quantile(df1.Price,0.25)\n",
    "    q3 = np.quantile(df1.Price,0.75)\n",
    "    med = np.median(df1.Price)\n",
    "    iqr = q3 - q1\n",
    "    upper_bound = q3+(1.5*iqr)\n",
    "    lower_bound = q1-(1.5*iqr)\n",
    "    if i > upper_bound or i < lower_bound:\n",
    "        df1['Price'] = df1['Price'].replace(i, np.median(df1['Price']))\n",
    "sns.boxplot(df1['Price'])\n",
    "plt.title('Price after median imputation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "725b9831",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data['Age']:\n",
    "    q1 = np.quantile(df1.Age,0.25)\n",
    "    q3 = np.quantile(df1.Age,0.75)\n",
    "    med = np.median(df1.Age)\n",
    "    iqr = q3 - q1\n",
    "    upper_bound = q3+(1.5*iqr)\n",
    "    lower_bound = q1-(1.5*iqr)\n",
    "    if i > upper_bound or i < lower_bound:\n",
    "        df1['Age'] = df1['Age'].replace(i, np.median(df1['Age']))\n",
    "sns.boxplot(df1['Age'])\n",
    "plt.title('Age after median imputation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f1b45bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data['KM']:\n",
    "    q1 = np.quantile(df1.KM,0.25)\n",
    "    q3 = np.quantile(df1.KM,0.75)\n",
    "    med = np.median(df1.KM)\n",
    "    iqr = q3 - q1\n",
    "    upper_bound = q3+(1.5*iqr)\n",
    "    lower_bound = q1-(1.5*iqr)\n",
    "    if i > upper_bound or i < lower_bound:\n",
    "        df1['KM'] = df1['KM'].replace(i, np.median(df1['KM']))\n",
    "sns.boxplot(df1['KM'])\n",
    "plt.title('KM after median imputation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48e29534",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data['Weight']:\n",
    "    q1 = np.quantile(df1.Weight,0.25)\n",
    "    q3 = np.quantile(df1.Weight,0.75)\n",
    "    med = np.median(df1.Weight)\n",
    "    iqr = q3 - q1\n",
    "    upper_bound = q3+(1.5*iqr)\n",
    "    lower_bound = q1-(1.5*iqr)\n",
    "    if i > upper_bound or i < lower_bound:\n",
    "        df1['Weight'] = df1['Weight'].replace(i, np.median(df1['Weight']))\n",
    "sns.boxplot(df1['Weight'])\n",
    "plt.title('Weight after median imputation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cda40d",
   "metadata": {},
   "source": [
    "### Let's test our data in model and find the R-squared with median imputation data model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2229eee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.34204996085646144, 0.3406706106695777)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_median_imputation_model = smf.ols(\"Price~Age+KM+Weight\", data = df1).fit()\n",
    "# Finding rsquared values\n",
    "after_median_imputation_model.rsquared , after_median_imputation_model.rsquared_adj "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01dbfe7",
   "metadata": {},
   "source": [
    "### Let's try Mean Imputation to handle Outlier in Profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8a6c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=data.copy()\n",
    "for i in data['Price']:\n",
    "    q1 = np.quantile(df2.Price,0.25)\n",
    "    q3 = np.quantile(df2.Price,0.75)\n",
    "    med = np.median(df2.Price)\n",
    "    iqr = q3 - q1\n",
    "    upper_bound = q3+(1.5*iqr)\n",
    "    lower_bound = q1-(1.5*iqr)\n",
    "    if i > upper_bound or i < lower_bound:\n",
    "        df2['Price'] = df2['Price'].replace(i, np.mean(df2['Price']))\n",
    "sns.boxplot(df2['Price'])\n",
    "plt.title('Price after mean imputation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ed71175",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data['Age']:\n",
    "    q1 = np.quantile(df2.Age,0.25)\n",
    "    q3 = np.quantile(df2.Age,0.75)\n",
    "    med = np.median(df2.Age)\n",
    "    iqr = q3 - q1\n",
    "    upper_bound = q3+(1.5*iqr)\n",
    "    lower_bound = q1-(1.5*iqr)\n",
    "    if i > upper_bound or i < lower_bound:\n",
    "        df2['Age'] = df2['Age'].replace(i, np.mean(df2['Age']))\n",
    "sns.boxplot(df2['Age'])\n",
    "plt.title('Age after mean imputation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8682e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data['KM']:\n",
    "    q1 = np.quantile(df2.KM,0.25)\n",
    "    q3 = np.quantile(df2.KM,0.75)\n",
    "    med = np.median(df2.KM)\n",
    "    iqr = q3 - q1\n",
    "    upper_bound = q3+(1.5*iqr)\n",
    "    lower_bound = q1-(1.5*iqr)\n",
    "    if i > upper_bound or i < lower_bound:\n",
    "        df2['KM'] = df2['KM'].replace(i, np.mean(df2['KM']))\n",
    "sns.boxplot(df2['KM'])\n",
    "plt.title('KM after mean imputation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907d2f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data['Weight']:\n",
    "    q1 = np.quantile(df2.Weight,0.25)\n",
    "    q3 = np.quantile(df2.Weight,0.75)\n",
    "    med = np.median(df2.Weight)\n",
    "    iqr = q3 - q1\n",
    "    upper_bound = q3+(1.5*iqr)\n",
    "    lower_bound = q1-(1.5*iqr)\n",
    "    if i > upper_bound or i < lower_bound:\n",
    "        df2['Weight'] = df2['Weight'].replace(i, np.mean(df2['Weight']))\n",
    "sns.boxplot(df2['Weight'])\n",
    "plt.title('Weight after mean imputation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499106f9",
   "metadata": {},
   "source": [
    "### Let's test our data in model and find the R-squared with mean imputation data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1438b515",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_mean_imputation_model = smf.ols(\"Price~Age+KM+Weight\", data = df2).fit()\n",
    "# Finding rsquared values\n",
    "after_mean_imputation_model.rsquared , after_mean_imputation_model.rsquared_adj "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5d184e",
   "metadata": {},
   "source": [
    "### ^Observation: As you can see after mean imputation the model is not performing well\n",
    "\n",
    "* Now we have to try something else to get out better results than the raw data\n",
    "\n",
    "### ^Observation: As you can see even after imputation the model is not performing well it getting worse\n",
    "\n",
    "* Now we have to try something else to get out model better than the raw data\n",
    "\n",
    "### The best thing we can do is now to remove the outlier and see the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a07fc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=data.copy()\n",
    "def drop_outliers(data, field_name):\n",
    "    iqr = 1.5*(np.percentile(data[field_name], 75) - np.percentile(data[field_name], 25))\n",
    "    data.drop(data[data[field_name] > (iqr + np.percentile(data[field_name], 75))].index, inplace=True)\n",
    "    data.drop(data[data[field_name] < (np.percentile(data[field_name], 25) - iqr)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f284439",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_outliers(df3, 'Price')\n",
    "sns.boxplot(df3.Price)\n",
    "plt.title('Price after removing outliers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65592abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_outliers(df3, 'Age')\n",
    "sns.boxplot(df3.Age)\n",
    "plt.title('Age after removing outliers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90489ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_outliers(df3, 'KM')\n",
    "sns.boxplot(df3.KM)\n",
    "plt.title('KM after removing outliers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49227e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_outliers(df3, 'Weight')\n",
    "sns.boxplot(df3.Weight)\n",
    "plt.title('Weight after removing outliers')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fef0c83",
   "metadata": {},
   "source": [
    "#### Let's test our data in model and compare the R-squared with without imputation data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e43f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_outlier_model = smf.ols(\"Price~Age+KM+Weight\", data = df3).fit()\n",
    "# Finding rsquared values\n",
    "removed_outlier_model.rsquared , removed_outlier_model.rsquared_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b261ce3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(removed_outlier_model.mse_resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271dec50",
   "metadata": {},
   "source": [
    "### Let's try log transformation and visualize the result first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4dc99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.copy()\n",
    "df[continuous_feature]=np.log(df[continuous_feature])\n",
    "    \n",
    "fig, axes=plt.subplots(4,1,figsize=(16,9),sharex=False,sharey=False)\n",
    "sns.boxplot(x='Price',data=df,palette='crest',ax=axes[0])\n",
    "sns.boxplot(x='Age',data=df,palette='crest',ax=axes[1])\n",
    "sns.boxplot(x='KM',data=df,palette='crest',ax=axes[2])\n",
    "sns.boxplot(x='Weight',data=df,palette='crest',ax=axes[3])\n",
    "plt.tight_layout(pad=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617f2167",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_transfomed = data.copy()\n",
    "log_transfomed[continuous_feature]=np.log(log_transfomed[continuous_feature])\n",
    "log_transformed_model = smf.ols(\"Price~Age+KM+Weight\", data = log_transfomed).fit()\n",
    "# Finding rsquared values\n",
    "log_transformed_model.rsquared , log_transformed_model.rsquared_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc067a10",
   "metadata": {},
   "source": [
    "### ^Observation: The outliers are still present\n",
    "\n",
    "### Let's try cuberoot transformation and visualize the result first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dccdd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.copy()\n",
    "df[continuous_feature]=np.cbrt(df[continuous_feature])\n",
    "\n",
    "fig, axes=plt.subplots(4,1,figsize=(16,9),sharex=False,sharey=False)\n",
    "sns.boxplot(x='Price',data=df,palette='crest',ax=axes[0])\n",
    "sns.boxplot(x='Age',data=df,palette='crest',ax=axes[1])\n",
    "sns.boxplot(x='KM',data=df,palette='crest',ax=axes[2])\n",
    "sns.boxplot(x='Weight',data=df,palette='crest',ax=axes[3])\n",
    "plt.tight_layout(pad=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81acd13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_root_transfomed = data.copy()\n",
    "cube_root_transfomed[continuous_feature]=np.cbrt(cube_root_transfomed[continuous_feature])\n",
    "cube_root_transformed_model = smf.ols(\"Price~Age+KM+Weight\", data = cube_root_transfomed).fit()\n",
    "# Finding rsquared values\n",
    "cube_root_transformed_model.rsquared , cube_root_transformed_model.rsquared_adj "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eb1d46",
   "metadata": {},
   "source": [
    "### ^Observation: The outliers are still present\n",
    "\n",
    "### ^Observation: After removing Outliers the model performed very poorly than the raw data model\n",
    "\n",
    "* Note: We will continue with different technique to deal with that\n",
    "\n",
    "## Raw Data Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210859b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081e252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_model = smf.ols(\"Price~Age+KM+Weight+HP+CC+Gears+QT+Doors\", data = data).fit()\n",
    "# Finding rsquared values\n",
    "raw_data_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85489e0f",
   "metadata": {},
   "source": [
    " Notes:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "[2] The condition number is large, 3.13e+06. This might indicate that there are\n",
    "strong multicollinearity or other numerical problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45357af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(raw_data_model.mse_resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9445c0",
   "metadata": {},
   "source": [
    "### Detecting Influencers/Outliers in the Model\n",
    "\n",
    "* Two Techniques : 1. Cook's Distance & 2. Leverage value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39762d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "influence_points=raw_data_model.get_influence()\n",
    "c, p_value=influence_points.cooks_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43503b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leverage Value using High Influence Points : Points beyond Leverage_cutoff value are influencers\n",
    "fig,ax=plt.subplots(figsize=(20,20))\n",
    "fig=influence_plot(raw_data_model,ax = ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc4bce3",
   "metadata": {},
   "source": [
    "### Leverage Cuttoff Value = 3*(k+1)/n ; k = no.of features/columns & n = no. of datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4397d46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=data.shape[1]\n",
    "n=data.shape[0]\n",
    "leverage_cutoff = (3*(k+1))/n\n",
    "print('Cut-off line at',np.round(leverage_cutoff,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fca354",
   "metadata": {},
   "source": [
    "#### Let's plot the influencers and also plot a cut off line using the stem plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd155bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (16,9))\n",
    "x = [0,48]\n",
    "y = [0.1,0.1]\n",
    "plt.plot(x, y,color='darkred', linewidth=2)\n",
    "y1 = [0.05,0.05]\n",
    "plt.plot(x , y1, color = 'red', linewidth = 2)\n",
    "plt.stem(np.arange(len(data)), np.round(c, 3))\n",
    "plt.xlabel('Row index')\n",
    "plt.ylabel(\"Cook's Distance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cea1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index and value of influencer where C>0.5\n",
    "np.argmax(c) , np.max(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b31551",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.index.isin([80])] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b92b3a2",
   "metadata": {},
   "source": [
    "### Let's improve the model by deleting the influence point and creating a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89e2bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe= data.copy()\n",
    "# Discard the data points which are influencers and reassign the row number (reset_index(drop=True))\n",
    "dataframe=dataframe.drop(dataframe.index[[80]],axis=0).reset_index(drop=True)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fafa613",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9993008f",
   "metadata": {},
   "source": [
    "### Model Deletion Diagnostics and Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cc4655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another Method\n",
    "\"\"\"k=dataframe.shape[1]\n",
    "n=dataframe.shape[0]\n",
    "leverage_cutoff = (3*(k+1))/n\n",
    "while np.max(c)>leverage_cutoff:\n",
    "    model=smf.ols('Price~Age+KM+HP+CC+Doors+Gears+QT+Weight',data=dataframe).fit()\n",
    "    (c,_)=model.get_influence().cooks_distance\n",
    "    c\n",
    "    np.argmax(c) , np.max(c)\n",
    "    dataframe=dataframe.drop(dataframe.index[[np.argmax(c)]],axis=0).reset_index(drop=True)\n",
    "    dataframe\n",
    "else:\n",
    "    final_model=smf.ols('Price~Age+KM+HP+CC+Doors+Gears+QT+Weight',data=dataframe).fit()\n",
    "    final_model.rsquared , final_model.aic\n",
    "    print(\"Thus model accuracy is improved to\",final_model.rsquared)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03a52c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while raw_data_model.rsquared < 0.90:\n",
    "    for c in [np.max(c)>leverage_cutoff]:\n",
    "        raw_data_model=smf.ols('Price~Age+KM+HP+CC+Doors+Gears+QT+Weight',data=dataframe).fit()\n",
    "        (c,_)=raw_data_model.get_influence().cooks_distance\n",
    "        c\n",
    "        np.argmax(c) , np.max(c)\n",
    "        dataframe=dataframe.drop(dataframe.index[[np.argmax(c)]],axis=0).reset_index(drop=True)\n",
    "        dataframe\n",
    "    else:\n",
    "        final_model=smf.ols('Price~Age+KM+HP+CC+Doors+Gears+QT+Weight',data=dataframe).fit()\n",
    "        final_model.rsquared , final_model.aic\n",
    "        print(\"Thus model accuracy is improved to\",final_model.rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e159651",
   "metadata": {},
   "outputs": [],
   "source": [
    "influence_points=final_model.get_influence()\n",
    "c, p_value=influence_points.cooks_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0f8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1292d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7647ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (16,9))\n",
    "x = [0,1330]\n",
    "y = [0.5,0.5]\n",
    "plt.plot(x, y,color='darkred', linewidth=2)\n",
    "y1 = [0.02,0.02]\n",
    "plt.plot(x , y1, color = 'red', linewidth = 2)\n",
    "plt.stem(np.arange(len(dataframe)), np.round(c, 3))\n",
    "plt.xlabel('Row index')\n",
    "plt.ylabel(\"Cook's Distance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7fcc08",
   "metadata": {},
   "source": [
    "### ^Observation: All the points are below our cut-off line\n",
    "\n",
    "* Hence, we can say that there are no influncers present in our model we can proceed with the predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bf6c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76214152",
   "metadata": {},
   "source": [
    "Notes:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "[2] The condition number is large, 4.34e+06. This might indicate that there are\n",
    "strong multicollinearity or other numerical problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7376ac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(final_model.mse_resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0878db18",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "### Applying some Data Transformation to increase the linear realtionship and improve our model prediction as well it scores\n",
    "\n",
    "### Log-Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394e248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log_scaled = pd.DataFrame()\n",
    "df_log_scaled['Age'] = np.log(dataframe.Age)\n",
    "df_log_scaled['Price'] = np.log(dataframe.Price)\n",
    "df_log_scaled['KM'] = np.log(dataframe.KM)\n",
    "df_log_scaled['Weight'] = np.log(dataframe.Weight)\n",
    "df_log_scaled['CC'] = dataframe['CC']\n",
    "df_log_scaled['Doors'] = dataframe['Doors']\n",
    "df_log_scaled['HP'] = dataframe['HP']\n",
    "df_log_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035c2e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_transformed_model = smf.ols(\"Price~Age+KM+HP+CC+Doors+Weight\", data = df_log_scaled).fit()\n",
    "# Finding rsquared values for Log transformation\n",
    "log_transformed_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a432bfb0",
   "metadata": {},
   "source": [
    "Notes:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "[2] The condition number is large, 6.06e+05. This might indicate that there are\n",
    "strong multicollinearity or other numerical problems.\n",
    "\n",
    "### Cube-Root Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020e63f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cbrt_scaled = pd.DataFrame()\n",
    "df_cbrt_scaled['Age'] = np.cbrt(dataframe.Age)\n",
    "df_cbrt_scaled['Price'] = np.cbrt(dataframe.Price)\n",
    "df_cbrt_scaled['KM'] = np.cbrt(dataframe.KM)\n",
    "df_cbrt_scaled['Weight'] = np.cbrt(dataframe.Weight)\n",
    "df_cbrt_scaled['CC'] = dataframe['CC']\n",
    "df_cbrt_scaled['QT'] = dataframe['QT']\n",
    "df_cbrt_scaled['Doors'] = dataframe['Doors']\n",
    "df_cbrt_scaled['Gears'] = dataframe['Gears']\n",
    "df_cbrt_scaled['HP'] = dataframe['HP']\n",
    "df_cbrt_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af11c490",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbrt_transformed_model = smf.ols(\"Price~Age+KM+HP+CC+Doors+Gears+QT+Weight\", data = df_cbrt_scaled).fit()\n",
    "# Finding rsquared values for Cube-Root transformation\n",
    "cbrt_transformed_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb463e4",
   "metadata": {},
   "source": [
    "Notes:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "[2] The condition number is large, 2.84e+05. This might indicate that there are\n",
    "strong multicollinearity or other numerical problems.\n",
    "\n",
    "### Square-Root Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65012ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sqrt_scaled = pd.DataFrame()\n",
    "df_sqrt_scaled['Age'] = np.sqrt(dataframe.Age)\n",
    "df_sqrt_scaled['Price'] = np.sqrt(dataframe.Price)\n",
    "df_sqrt_scaled['KM'] = np.sqrt(dataframe.KM)\n",
    "df_sqrt_scaled['Weight'] = np.sqrt(dataframe.Weight)\n",
    "df_sqrt_scaled['CC'] = dataframe['CC']\n",
    "df_sqrt_scaled['QT'] = dataframe['QT']\n",
    "df_sqrt_scaled['Doors'] = dataframe['Doors']\n",
    "df_sqrt_scaled['Gears'] = dataframe['Gears']\n",
    "df_sqrt_scaled['HP'] = dataframe['HP']\n",
    "df_sqrt_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3195e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_transformed_model = smf.ols(\"Price~Age+KM+HP+CC+Doors+Gears+QT+Weight\", data = df_sqrt_scaled).fit()\n",
    "# Finding rsquared values for Square-Root transformation\n",
    "sqrt_transformed_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ef7a8f",
   "metadata": {},
   "source": [
    "Notes:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "[2] The condition number is large, 1.85e+05. This might indicate that there are\n",
    "strong multicollinearity or other numerical problems.\n",
    "\n",
    "### Let's try Robust transformation\n",
    "\n",
    "The Robust Scaler, as the name suggests is not sensitive to outliers.\n",
    "\n",
    "* This scaler removes the median from the data\n",
    "* Scales the data by the InterQuartile Range(IQR)\n",
    "\n",
    "The interquartile range can be defined as-\n",
    "\n",
    "IQR = Q3 – Q1\n",
    "\n",
    "Thus, the formula would be:\n",
    "\n",
    "x_scaled = (x – Q1)/(Q3 – Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a601db95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_robust_scaled = dataframe.copy()\n",
    "columns= ['Price','Age','KM','Weight']\n",
    "features = df_robust_scaled[columns]\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "df_robust_scaled[columns] = scaler.fit_transform(features.values)\n",
    "df_robust_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa796e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_transformed_model = smf.ols(\"Price~Age+KM+HP+CC+Doors+Gears+QT+Weight\", data = df_robust_scaled).fit()\n",
    "# Finding rsquared values for robust transformation\n",
    "robust_transformed_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea9ff09",
   "metadata": {},
   "source": [
    "Notes:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "[2] The condition number is large, 5.32e+04. This might indicate that there are\n",
    "strong multicollinearity or other numerical problems.\n",
    "\n",
    "### Applying Standard Scaler\n",
    "\n",
    "* For each feature, the Standard Scaler scales the values such that the mean is 0 and the standard deviation is 1(or the variance).\n",
    "* x_scaled = x – mean/std_dev\n",
    "* However, Standard Scaler assumes that the distribution of the variable is normal. Thus, in case, the variables are not normally distributed, we either choose a different scaler or first, convert the variables to a normal distribution and then apply this scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e65d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "col_names = dataframe.columns\n",
    "features = dataframe[col_names]\n",
    "\n",
    "scaler = StandardScaler().fit(features.values)\n",
    "features = scaler.transform(features.values)\n",
    "df_standard_scaled = pd.DataFrame(features, columns = col_names)\n",
    "df_standard_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3a8006",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler_transformed_model = smf.ols(\"Price~Age+KM+HP+CC+Doors+Gears+QT+Weight\", data = df_standard_scaled).fit()\n",
    "# Finding rsquared values for standard scaler transformation\n",
    "standard_scaler_transformed_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7c788d",
   "metadata": {},
   "source": [
    "Notes:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "\n",
    "### ^Observation: After the transformation and building models the R-Squared had varince with respect to other transformations\n",
    "* But standard scaler is better than raw data model and other models with better AIC, BIC log-likelihood scores\n",
    "* We have to perform model validation test to check which model is better will do at the end of this\n",
    "\n",
    "### For building Multi Linear Resgression there are assumption regarding the data set.\n",
    "\n",
    "### They are as follows:-\n",
    "1. Feature should be independent of each other there should'nt be any dependency upon each other\n",
    "2. There shouldn't any other relation but Linear relation amongst model parameters (Hyperparameters of the model the intercept and coefficient)\n",
    "3. Each Feature and Model Error (residuals) should be independent of each other\n",
    "4. Constant Variance (Homoscedasticity) in Error, it should have Normal / Gaussian distribution~N(0,1) and idenpendently and identically distributed.\n",
    "5. There should be a linear relation between the dependent variable and Independent variables\n",
    "\n",
    "We will Check the above one by one\n",
    "\n",
    "### Preparing a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8ca7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols(\"Price~Age+KM+HP+CC+Doors+Gears+QT+Weight\", data = df_standard_scaled).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a77d816",
   "metadata": {},
   "source": [
    "Notes:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "\n",
    "* Summary The values we are concerned with are -\n",
    "The coefficients and significance (p-values) R-squared F statistic and its significance\n",
    "\n",
    "1. R - squared is 0.896 Meaning that 89.9% of the variance in cnt with registered\n",
    "This is a decent R-squared value.\n",
    "\n",
    "3. F statistic has a very low p value (practically low) Meaning that the model fit is statistically significant, and the explained variance isn't purely by chance.\n",
    "\n",
    "Note: If any of the above step is not followed our model can't be a good predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f905988",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (16,9))\n",
    "sm.graphics.plot_regress_exog(model, 'Gears', fig=fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0a8235",
   "metadata": {},
   "source": [
    "### ^Observation No Linear Relation found in QT Feature with the Dependent feature\n",
    "\n",
    "### Model Testing\n",
    "### As Y = Beta0 + Beta1(X1) + Beta2(X2) +Beta3(X3) + .................. + Beta n(Xn)\n",
    "\n",
    "### Finding Coefficient Parameters (Beta0 and Beta1's values)\n",
    "Assupmtion for multi linear Regression fails\n",
    "\n",
    "Feature should be independent of each other there should'nt be any dependency upon each other\n",
    "\n",
    "### Here, (Intercept) Beta0 p_value ~ 1\n",
    "\n",
    "### Hypothesis testing of X variable by finding test_statistics and P_values for Beta1 i.e if (P_value < α=0.05 ; Reject Null)\n",
    "\n",
    "### Null Hypothesis as Beta1=0 (No Slope) and Alternate Hypthesis as Beta1≠0 (Some or significant Slope)\n",
    "\n",
    "### ^Observation: If the p-value is not less than .05 for Gears features, we fail to reject the null hypothesis. We do not have sufficient evidence to say that the sample data providing those features dependency towards the dependent variable\n",
    "* Looking at the p-values, it looks like some of the variables aren't really significant (in the presence of other variables).\n",
    "\n",
    "* Maybe we could drop some?\n",
    "\n",
    "* We could simply drop the variable with the highest, non-significant p value. A better way would be to supplement this with the VIF information.\n",
    "\n",
    "### Let's Try another Test by Calculating VIF ( Variance Inflation Factor )\n",
    "\n",
    "* This helps to check the dependency among the features by building a model without the target and testing various combination among the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bab3d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "y = df_standard_scaled.drop(['Price'], axis=1)\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = y.columns\n",
    "vif['VIF'] = [variance_inflation_factor(y.values, i) for i in range(y.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043154be",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sqr_age = smf.ols('Age~HP+Weight+CC+Doors+QT+Gears+KM', dataframe).fit().rsquared\n",
    "vif_age = 1/(1-r_sqr_age)\n",
    "r_sqr_weight = smf.ols('Weight~HP+Age+CC+Doors+QT+Gears+KM', dataframe).fit().rsquared\n",
    "vif_weight = 1/(1-r_sqr_weight)\n",
    "r_sqr_cc = smf.ols('CC~HP+Weight+Age+Doors+QT+Gears+KM', dataframe).fit().rsquared\n",
    "vif_cc = 1/(1-r_sqr_cc)\n",
    "r_sqr_hp = smf.ols('HP~Age+Weight+CC+Doors+QT+Gears+KM', dataframe).fit().rsquared\n",
    "vif_hp = 1/(1-r_sqr_hp)\n",
    "r_sqr_qt = smf.ols('QT~HP+Weight+CC+Doors+Age+Gears+KM', dataframe).fit().rsquared\n",
    "vif_qt = 1/(1-r_sqr_qt)\n",
    "r_sqr_km = smf.ols('KM~HP+Weight+CC+Doors+QT+Gears+Age', dataframe).fit().rsquared\n",
    "vif_km = 1/(1-r_sqr_km)\n",
    "r_sqr_gears = smf.ols('Gears~HP+Weight+CC+Doors+QT+Age+KM', dataframe).fit().rsquared\n",
    "vif_gears = 1/(1-r_sqr_gears)\n",
    "r_sqr_doors = smf.ols('Doors~HP+Weight+CC+Age+QT+Gears+KM', dataframe).fit().rsquared\n",
    "vif_doors = 1/(1-r_sqr_doors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd29e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_frame = pd.DataFrame({'Variables':['Doors','HP','Weight','CC','Age','QT','Gears','KM'], 'VIF':[vif_doors,vif_hp,vif_weight,vif_cc,vif_age,vif_qt,vif_gears,vif_km]}, index = None)\n",
    "vif_frame.set_index('Variables', inplace = True)\n",
    "vif_frame.sort_values(by = 'VIF')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a1f2bd",
   "metadata": {},
   "source": [
    "## Note: We generally want a VIF that is less than 5. As you can see QT has the highest value among others lets investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d01a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple Linear Model using QT\n",
    "qt_model = smf.ols('Price~QT', data=df_standard_scaled).fit()\n",
    "qt_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562e3227",
   "metadata": {},
   "source": [
    "Notes:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322cd958",
   "metadata": {},
   "outputs": [],
   "source": [
    "gears_model = smf.ols('Price~Gears', data=df_standard_scaled).fit()\n",
    "gears_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40db7fbc",
   "metadata": {},
   "source": [
    "Notes:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be7451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gears_qt_weight_model = smf.ols('Price~Gears+QT', data=df_standard_scaled).fit()\n",
    "gears_qt_weight_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93ff5a2",
   "metadata": {},
   "source": [
    "Notes:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "\n",
    "### Significance level - Backward elimination\n",
    "\n",
    "We have different techniques to find out the features which have the maximum effect on the output.\n",
    "\n",
    "Here we are going to look at the Backward elimination.\n",
    "\n",
    "In this process we need to add one column of ones in the starting of the column.\n",
    "\n",
    "In backward elimination we delete the value one by one whose significance level is less.\n",
    "\n",
    "i.e In general we have a P-value and a significance level\n",
    "\n",
    "P_value = 1 - (minus) significane level\n",
    "\n",
    "or in other terms\n",
    "\n",
    "p_value+ significance level = 1\n",
    "\n",
    "if P_value is high significance level is less.\n",
    "\n",
    "Hence we will be deleating features one by one whose P_value is high which means it has less significance level.\n",
    "\n",
    "By eliminating process we get to the values which are of most significance\n",
    "\n",
    "### Model1\n",
    "\n",
    "* Dropping the variable and updating the model\n",
    "* As you can see from the summary and the VIF dataframe, some variables are still insignificant. One of these variables is, Gears as it has a very high P Value of 0.75 in SLR and 0.12 in MLR has R square score of 0. Let's go ahead and drop this variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86e183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping highly correlated variables and insignificant variables\n",
    "\n",
    "x = df_standard_scaled.drop(['Gears'], axis=1)\n",
    "y = df_standard_scaled.drop(['Gears','Price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01161c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f00699",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = smf.ols('Price ~ Age + KM + HP + CC + Doors + QT + Weight', data = x).fit()\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610ae975",
   "metadata": {},
   "source": [
    "Notes:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "\n",
    "### ^Observation: As our Multicollinearity problem has been solved\n",
    "\n",
    "### Feature Selection Techniques in Machine Learning\n",
    "\n",
    "\n",
    "### Correlation Coefficient\n",
    "\n",
    "Correlation is a measure of the linear relationship of 2 or more variables. Through correlation, we can predict one variable from the other. The logic behind using correlation for feature selection is that the good variables are highly correlated with the target. Furthermore, variables should be correlated with the target but should be uncorrelated among themselves.\n",
    "\n",
    "If two variables are correlated, we can predict one from the other. Therefore, if two features are correlated, the model only really needs one of them, as the second one does not add additional information. We will use the Pearson Correlation here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d54e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb82205",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(data.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64ddc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(style='darkgrid')\n",
    "sns.pairplot(data[continuous_feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72abeee4",
   "metadata": {},
   "source": [
    "### ^Observation: Age and KM has the highest score of correlation with Price but a negative correlation\n",
    "\n",
    "Note: QT and Weight also have a collinearity among themselves which will affect our model.\n",
    "Note: KM and Age also have a collinearity among themselves which will affect our model.\n",
    "    \n",
    "### PCA on Standard Scaled Dataset\n",
    "\n",
    "##### Explained variance\n",
    "\n",
    "Explained variance shows how much of the variance/spread of the data is captured in each dimension, i.e. how important each additional principal component is to the original data representation.\n",
    "\n",
    "##### Let's seperate the x and y values    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29680721",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_standard_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ca5b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = df_standard_scaled.values\n",
    "x = array[:,1:]\n",
    "y = array[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc43a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "pca_var = PCA()\n",
    "pca_var.fit(x)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10,5))\n",
    "xi = np.arange(1, 1+x.shape[1], step=1)\n",
    "yi = np.cumsum(pca_var.explained_variance_ratio_)\n",
    "plt.plot(xi, yi, marker='o', linestyle='--', color='b')\n",
    "\n",
    "# Aesthetics\n",
    "plt.ylim(0.0,1.1)\n",
    "plt.xlabel('Number of Components')\n",
    "plt.xticks(np.arange(1, 1+x.shape[1], step=1))\n",
    "plt.ylabel('Cumulative variance (%)')\n",
    "plt.title('Explained variance by each component')\n",
    "plt.axhline(y=1, color='r', linestyle='-')\n",
    "plt.gca().xaxis.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763dbea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the amount of variance that each PCA explains is \n",
    "var = pca_var.explained_variance_ratio_\n",
    "var "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b147acc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(1, len(var)+1),var)\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('variance (%)')\n",
    "plt.title('Explained variance by each component')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed30e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative Variance\n",
    "var1 = np.cumsum(np.round(var,decimals = 4)*100)\n",
    "var1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1d1c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "pca = PCA()\n",
    "pca_std = pca.fit_transform(x)\n",
    "\n",
    "# Convert to data frame\n",
    "pca_std_df = pd.DataFrame(data = pca_std, columns = ['PC1', 'PC2','PC3','PC4', 'PC5','PC6','PC7','PC8'])\n",
    "\n",
    "# Shape and preview\n",
    "print(pca_std_df.shape)\n",
    "pca_std_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe9d681",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af20d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_std_df['Price'] = y\n",
    "pca_std_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140cbf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "pca_model= sm.ols('Price~PC1+PC2+PC3+PC4+PC5+PC6+PC7+PC8', data= pca_std_df).fit()\n",
    "pca_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa62fb73",
   "metadata": {},
   "source": [
    "Notes:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcca376",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_y = StandardScaler().fit(dataframe['Price'].to_numpy().reshape(-1,1))\n",
    "# Scale the test dataset\n",
    "y_train_scal = transformer_y.transform(dataframe['Price'].to_numpy().reshape(-1,1))\n",
    "\n",
    "# Predict with the trained model\n",
    "predict = pd.DataFrame(pca_model.predict(pca_std_df))\n",
    "\n",
    "# Inverse transform the prediction\n",
    "predict_unscaled = transformer_y.inverse_transform(predict.values.reshape(-1,1))\n",
    "\n",
    "# Predicting RMSE the Test set results\n",
    "rmse_linear= (np.sqrt(mean_squared_error(dataframe.Price, predict_unscaled)))\n",
    "print('R2_score : ', pca_model.rsquared)\n",
    "print('R2_Adjusted_score : ', pca_model.rsquared_adj)\n",
    "print(\"RMSE : \", rmse_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982eec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_std_df['Price'] = dataframe['Price']\n",
    "pca_std_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442aea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(pca_std_df.iloc[:,:-1], pca_std_df.iloc[:,-1],test_size=0.3,random_state=0)\n",
    "\n",
    "x_train.shape, x_test.shape , y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680cf947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Scaling \n",
    "transformer_y = StandardScaler().fit(y_train.to_numpy().reshape(-1,1)) \n",
    "y_train_scal = transformer_y.transform(y_train.to_numpy().reshape(-1,1))\n",
    "y_test_scal = transformer_y.transform(y_test.to_numpy().reshape(-1,1))\n",
    "\n",
    "#Linear Regression\n",
    "regressor_linear = LinearRegression()\n",
    "regressor_linear.fit(x_train, y_train_scal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020e7989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with the trained model\n",
    "prediction = regressor_linear.predict(x_test)\n",
    "\n",
    "# Inverse transform the prediction\n",
    "prediction_unscaled = transformer_y.inverse_transform(prediction)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Predicting Cross Validation Score the Test set results\n",
    "cv_linear = cross_val_score(estimator = regressor_linear, X = x_train, y = y_train_scal, cv = 10)\n",
    "\n",
    "# Predicting R2 Score the Train set results\n",
    "y_pred_linear_train = regressor_linear.predict(x_train)\n",
    "r2_score_all_feature_train = r2_score(y_train_scal, y_pred_linear_train)\n",
    "\n",
    "# Predicting R2 Score the Test set results\n",
    "y_pred_linear_test = regressor_linear.predict(x_test)\n",
    "r2_score_all_feature_test = r2_score(y_test_scal, y_pred_linear_test)\n",
    "\n",
    "# Predicting RMSE the Test set results\n",
    "rmse_linear_using_all_features = (np.sqrt(mean_squared_error(y_test, prediction_unscaled)))\n",
    "print(\"CV: \", cv_linear.mean())\n",
    "print('R2_score (train): ', r2_score_all_feature_train)\n",
    "print('R2_score (test): ', r2_score_all_feature_test)\n",
    "print(\"RMSE using all features: \", rmse_linear_using_all_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93b27f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataframe.drop('Price', axis =1)\n",
    "Y = dataframe[['Price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021c6f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find and remove correlated features\n",
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr\n",
    "\n",
    "corr_features = correlation(X, 0.8)\n",
    "print('correlated features: ', len(set(corr_features)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb2a070",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# find and remove correlated features\n",
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if (corr_matrix.iloc[i, j]) < threshold: # we are interested in absolute coeff value\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr\n",
    "\n",
    "corr_features = correlation(X, -0.8)\n",
    "print('correlated features: ', len(set(corr_features)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be33ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y,test_size=0.3,random_state=0)\n",
    "\n",
    "x_train.shape, x_test.shape , y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e0306b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b484b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step forward feature selection\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "# step forward feature selection\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "sfs1 = SFS(RandomForestRegressor(), \n",
    "           k_features=4, \n",
    "           forward=True, \n",
    "           floating=False, \n",
    "           verbose=2,\n",
    "           scoring='r2',\n",
    "           cv=3)\n",
    "\n",
    "sfs1 = sfs1.fit(np.array(x_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e6b2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs1.k_feature_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d489846",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.columns[list(sfs1.k_feature_idx_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea6c7e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# checking the magnitude of coefficients\n",
    "import statsmodels.formula.api as sm\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f = 'Price ~ Age + KM + HP + CC + Doors + Weight + QT + Gears'\n",
    "reg_results = sm.ols(f, data=dataframe).fit()\n",
    "\n",
    "err_series = reg_results.params - reg_results.conf_int()[0]\n",
    "err_series\n",
    "\n",
    "coef_df = pd.DataFrame({'coef': reg_results.params.values[1:],\n",
    "                        'err': err_series.values[1:],\n",
    "                        'varname': err_series.index.values[1:]\n",
    "                       })\n",
    "print(coef_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e70c8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the magnitude of coefficients\n",
    "\n",
    "coef = pd.Series(data = coef_df.coef.values,index = coef_df.varname).sort_values()\n",
    "\n",
    "coef.plot(kind='bar', title='Modal Coefficients')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67a7b3b",
   "metadata": {},
   "source": [
    "### Ridge Regression\n",
    "\n",
    "Let us first implement it on our above problem and check our results that whether it performs better than our linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852b98f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "## training the model\n",
    "\n",
    "ridgeReg = Ridge(alpha=0.05, normalize=True)\n",
    "\n",
    "ridgeReg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d47676c",
   "metadata": {},
   "source": [
    "* Note that value of alpha, which is hyperparameter of Ridge, which means that they are not automatically learned by the model instead they have to be set manually.\n",
    "\n",
    "Here we have consider alpha = 0.05. But let us consider different values of alpha and plot the coefficients for each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dab004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Predicting Cross Validation Score the Test set results\n",
    "cv_ridge = cross_val_score(estimator = ridgeReg, X = x_train, y = y_train, cv = 10)\n",
    "\n",
    "# Predicting R2 Score the Train set results\n",
    "y_pred_ridge_train = ridgeReg.predict(x_train)\n",
    "r2_score_ridge_train = r2_score(y_train, y_pred_ridge_train)\n",
    "\n",
    "# Predicting R2 Score the Test set results\n",
    "y_pred_ridge_test = ridgeReg.predict(x_test)\n",
    "r2_score_ridge_test = r2_score(y_test, y_pred_ridge_test)\n",
    "\n",
    "# Predicting RMSE the Test set results\n",
    "rmse_ridge = (np.sqrt(mean_squared_error(y_test, y_pred_ridge_test)))\n",
    "print(\"CV: \", cv_ridge.mean())\n",
    "print('R2_score (train): ', r2_score_ridge_train)\n",
    "print('R2_score (test): ', r2_score_ridge_test)\n",
    "print(\"RMSE: \", rmse_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5d22dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgeReg.coef_.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194672a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame({'coef': ridgeReg.coef_.flatten(),\n",
    "                        'varname': dataframe.columns.values[1:]\n",
    "                       })\n",
    "print(coef_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cef9bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the magnitude of coefficients\n",
    "\n",
    "coef = pd.Series(data = coef_df.coef.values,index = coef_df.varname).sort_values()\n",
    "\n",
    "coef.plot(kind='bar', title='alpha = 0.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f2d2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the magnitude of coefficients\n",
    "\n",
    "coef = pd.Series(data = coef_df.coef.values,index = coef_df.varname).sort_values()\n",
    "\n",
    "coef.plot(kind='bar', title='alpha = 0.05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310880b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the magnitude of coefficients\n",
    "\n",
    "coef = pd.Series(data = coef_df.coef.values,index = coef_df.varname).sort_values()\n",
    "\n",
    "coef.plot(kind='bar', title='alpha = 0.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a707f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the magnitude of coefficients\n",
    "\n",
    "coef = pd.Series(data = coef_df.coef.values,index = coef_df.varname).sort_values()\n",
    "\n",
    "coef.plot(kind='bar', title='alpha = 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfa1b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the magnitude of coefficients\n",
    "\n",
    "coef = pd.Series(data = coef_df.coef.values,index = coef_df.varname).sort_values()\n",
    "\n",
    "coef.plot(kind='bar', title='alpha = 10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d81093",
   "metadata": {},
   "source": [
    "You can see that, as we increase the value of alpha, the magnitude of the coefficients decreases.\n",
    "\n",
    "But if you calculate R-square for each alpha, we will see that the value of R-square will be maximum at alpha=0.05. So we have to choose it wisely by iterating it through a range of values and using the one which gives us lowest error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebc0264",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "steps = [\n",
    "    ('scalar', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('model', Ridge(alpha=0.5, fit_intercept=True))\n",
    "]\n",
    "\n",
    "ridge_pipe = Pipeline(steps)\n",
    "ridge_pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1576521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Predicting Cross Validation Score the Test set results\n",
    "cv_ridge = cross_val_score(estimator = ridge_pipe, X = x_train, y = y_train.values.ravel(), cv = 10)\n",
    "\n",
    "# Predicting R2 Score the Test set results\n",
    "y_pred_ridge_train = ridge_pipe.predict(x_train)\n",
    "r2_score_ridge_train = r2_score(y_train, y_pred_ridge_train)\n",
    "\n",
    "# Predicting R2 Score the Test set results\n",
    "y_pred_ridge_test = ridge_pipe.predict(x_test)\n",
    "r2_score_ridge_test = r2_score(y_test, y_pred_ridge_test)\n",
    "\n",
    "# Predicting RMSE the Test set results\n",
    "rmse_ridge = (np.sqrt(mean_squared_error(y_test, y_pred_ridge_test)))\n",
    "print('CV: ', cv_ridge.mean())\n",
    "print('R2_score (train): ', r2_score_ridge_train)\n",
    "print('R2_score (test): ', r2_score_ridge_test)\n",
    "print(\"RMSE: \", rmse_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309893ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, again I will train a Ridge Linear regression and select\n",
    "# the non zero features in one line.\n",
    "# bear in mind that the linear regression object from sklearn does\n",
    "# not allow for regularisation. So If you want to make a regularised\n",
    "# linear regression you need to import specifically \"Ridge\"\n",
    "# that is the l1 version of the linear regression\n",
    "# alpha is the penalisation here, so I set it high in order\n",
    "# to force the algorithm to shrink some coefficients\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "sel_ridge = SelectFromModel(Ridge(alpha=0.05))\n",
    "sel_ridge.fit(x_train, y_train)\n",
    "\n",
    "sel_ridge.get_support()\n",
    "\n",
    "# make a list with the selected features and print the outputs\n",
    "selected_feat = x_train.columns[(sel_ridge.get_support())]\n",
    "\n",
    "print('total features: {}'.format((x_train.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feat)))\n",
    "\n",
    "print(x_train.columns[(sel_ridge.get_support())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7364e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lassoReg = Lasso(alpha=0.5, normalize=True)\n",
    "\n",
    "lassoReg.fit(x_train,y_train)\n",
    "\n",
    "pred = lassoReg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258ebb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Predicting Cross Validation Score the Test set results\n",
    "cv_ridge = cross_val_score(estimator = lassoReg, X = x_train, y = y_train, cv = 10)\n",
    "\n",
    "# Predicting R2 Score the Train set results\n",
    "y_pred_lasso_train = lassoReg.predict(x_train)\n",
    "r2_score_lasso_train = r2_score(y_train, y_pred_lasso_train)\n",
    "\n",
    "# Predicting R2 Score the Test set results\n",
    "y_pred_lasso_test = lassoReg.predict(x_test)\n",
    "r2_score_lasso_test = r2_score(y_test, y_pred_lasso_test)\n",
    "\n",
    "# Predicting RMSE the Test set results\n",
    "rmse_ridge = (np.sqrt(mean_squared_error(y_test, y_pred_lasso_test)))\n",
    "print(\"CV: \", cv_ridge.mean())\n",
    "print('R2_score (train): ', r2_score_lasso_train)\n",
    "print('R2_score (test): ', r2_score_lasso_test)\n",
    "print(\"RMSE: \", rmse_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdc6817",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame({'coef': lassoReg.coef_.flatten(),\n",
    "                        'varname': dataframe.columns.values[1:]\n",
    "                       })\n",
    "print(coef_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55982d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the magnitude of coefficients\n",
    "\n",
    "coef = pd.Series(data = coef_df.coef.values,index = coef_df.varname).sort_values()\n",
    "\n",
    "coef.plot(kind='bar', title='alpha = 0.05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a609e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the magnitude of coefficients\n",
    "\n",
    "coef = pd.Series(data = coef_df.coef.values,index = coef_df.varname).sort_values()\n",
    "\n",
    "coef.plot(kind='bar', title='alpha = 0.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5f296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "steps = [\n",
    "    ('scalar', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('model', Lasso(alpha=0.5, fit_intercept=True, tol = 0.0199, max_iter=2000))\n",
    "]\n",
    "\n",
    "lasso_pipe = Pipeline(steps)\n",
    "lasso_pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1d73c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Predicting Cross Validation Score\n",
    "cv_lasso = cross_val_score(estimator = lasso_pipe, X = x_train, y = y_train, cv = 10)\n",
    "\n",
    "# Predicting R2 Score the Test set results\n",
    "y_pred_lasso_train = lasso_pipe.predict(x_train)\n",
    "r2_score_lasso_train = r2_score(y_train, y_pred_lasso_train)\n",
    "\n",
    "# Predicting R2 Score the Test set results\n",
    "y_pred_lasso_test = lasso_pipe.predict(x_test)\n",
    "r2_score_lasso_test = r2_score(y_test, y_pred_lasso_test)\n",
    "\n",
    "# Predicting RMSE the Test set results\n",
    "rmse_lasso = (np.sqrt(mean_squared_error(y_test, y_pred_lasso_test)))\n",
    "print('CV: ', cv_lasso.mean())\n",
    "print('R2_score (train): ', r2_score_lasso_train)\n",
    "print('R2_score (test): ', r2_score_lasso_test)\n",
    "print(\"RMSE: \", rmse_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ccafbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890bce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, again I will train a Lasso Linear regression and select\n",
    "# the non zero features in one line.\n",
    "# bear in mind that the linear regression object from sklearn does\n",
    "# not allow for regularisation. So If you want to make a regularised\n",
    "# linear regression you need to import specifically \"Lasso\"\n",
    "# that is the l1 version of the linear regression\n",
    "# alpha is the penalisation here, so I set it high in order\n",
    "# to force the algorithm to shrink some coefficients\n",
    "\n",
    "sel_lasso = SelectFromModel(Lasso(alpha=100))\n",
    "sel_lasso.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0171e5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_lasso.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dfa061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list with the selected features and print the outputs\n",
    "selected_feat = x_train.columns[(sel_lasso.get_support())]\n",
    "\n",
    "print('total features: {}'.format((x_train.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feat)))\n",
    "print('features with coefficients shrank to zero: {}'.format(np.sum(sel_lasso.estimator_.coef_ == 0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94a56a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.columns[(sel_lasso.get_support())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cef291",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataframe[['Age','KM','HP','CC','Doors','QT','Weight']]\n",
    "y = dataframe[['Price']]\n",
    "transformer_x = StandardScaler().fit(x)\n",
    "transformer_y = StandardScaler().fit(y)\n",
    "# Scale the test dataset\n",
    "x_train_scal = transformer_x.transform(x)\n",
    "y_train_scal = transformer_y.transform(y)\n",
    "\n",
    "# Linear Regression\n",
    "x_df = pd.DataFrame(x_train_scal, columns = ['Age','KM','HP','CC','Doors','QT','Weight'])\n",
    "x_df.head()\n",
    "\n",
    "# Predict with the trained model\n",
    "predict = pd.DataFrame(model_1.predict(x_df))\n",
    "\n",
    "# Inverse transform the prediction\n",
    "predict_unscaled = transformer_y.inverse_transform(predict.values.reshape(-1,1))\n",
    "\n",
    "# Predicting RMSE the Test set results\n",
    "rmse_linear= (np.sqrt(mean_squared_error(y, predict_unscaled)))\n",
    "print('R2_score : ', model_1.rsquared)\n",
    "print('R2_Adjusted_score : ', model_1.rsquared_adj)\n",
    "print(\"RMSE : \", rmse_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb13275",
   "metadata": {},
   "outputs": [],
   "source": [
    "square_root_pred_y =np.square(sqrt_transformed_model.predict(df_sqrt_scaled[['Age','Weight','KM','HP','CC','QT','Doors','Gears']]))\n",
    "cube_root_pred_y =pow(cbrt_transformed_model.predict(df_cbrt_scaled[['Age','Weight','KM','HP','CC','QT','Doors','Gears']]),3)\n",
    "log_model_pred_y =np.exp(log_transformed_model.predict(df_log_scaled[['Age','Weight','KM','HP','CC','Doors']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d9b017",
   "metadata": {},
   "outputs": [],
   "source": [
    "square_root_both_rmse =np.sqrt(mean_squared_error(dataframe['Price'], square_root_pred_y))\n",
    "cube_root_both_rmse =np.sqrt(mean_squared_error(dataframe['Price'], cube_root_pred_y))\n",
    "log_both_rmse =np.sqrt(mean_squared_error(dataframe['Price'], log_model_pred_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffde2ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Raw Model=', np.sqrt(raw_data_model.mse_resid),\n",
    "      '\\n''After Removing Influencers=', np.sqrt(final_model.mse_resid),\n",
    "      '\\n''After Log Transformation on both Model=', log_both_rmse,\n",
    "      '\\n''After Cube-root Transformation on both Model=', cube_root_both_rmse,\n",
    "     '\\n''After Sqaure Root Transformation on both Model=', square_root_both_rmse,\n",
    "      '\\n''After Removing Influencers from model', np.sqrt(final_model.mse_resid),\n",
    "     '\\n''Final Model without Multicollinearity Model=', rmse_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98450fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_compare = {'Raw Model': np.sqrt(raw_data_model.mse_resid),\n",
    "      'After Removing Influencers': np.sqrt(final_model.mse_resid),\n",
    "      'After Log Transformation Model': log_both_rmse,\n",
    "      'After Cube-root Transformation Model': cube_root_both_rmse,\n",
    "     'After Sqaure Root Transformation Model': square_root_both_rmse,\n",
    "                'After Removing Influencers from model': np.sqrt(final_model.mse_resid),\n",
    "   'Final Model without Multicollinearity Model': rmse_linear}\n",
    "min(rmse_compare, key=rmse_compare.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102c5a24",
   "metadata": {},
   "source": [
    "### ^Observation: The Model that was build without Multicollinearity Issue and using Standard Scaler Transformation performed very well.\n",
    "\n",
    "* Scoring minimumn Root mean squared error and a good R-squared and adjusted R-squared\n",
    "* Note: We are going to rebuild the model by using that model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c0c15b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63558d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Final_model = smf.ols(formula=\"Price ~Age + KM + HP + CC + Doors + QT + Weight\", data = x).fit()\n",
    "# Finding rsquared values\n",
    "Final_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddef9baa",
   "metadata": {},
   "source": [
    "Notes:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "\n",
    "### Residual Analysis\n",
    "\n",
    "* Test for Normality of Residuals (Q-Q Plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c27a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Residuals values  = y - yhat\n",
    "sm.qqplot(Final_model.resid, line = 'q')\n",
    "plt.title('Normal Q-Q plot of residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f2d072",
   "metadata": {},
   "source": [
    "##### ^Observation: Error should have Normal / Gaussian distribution~N(0,1) and idenpendently and identically distributed.\n",
    "\n",
    "### Residual Plot for Homoscedasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a048ca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standardized_values( vals ):\n",
    "    return (vals - vals.mean())/vals.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118aa824",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(get_standardized_values(Final_model.fittedvalues), get_standardized_values(Final_model.resid))\n",
    "plt.title('Residual Plot')\n",
    "plt.xlabel('Standardized Fitted Values')\n",
    "plt.ylabel('Standardized Residual Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc3c7f0",
   "metadata": {},
   "source": [
    "### ^Observation: Constant Variance (Homoscedasticity) in Error\n",
    "\n",
    "### Residual VS Regressors\n",
    "\n",
    "* Plotting to visualize the partial relation of each independent feature with the Dependent variable and errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53fa660",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (16,9))\n",
    "sm.graphics.plot_regress_exog(Final_model, 'Age', fig=fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e4c102",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (16,9))\n",
    "sm.graphics.plot_regress_exog(Final_model, 'HP', fig=fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a6a9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (16,9))\n",
    "sm.graphics.plot_regress_exog(Final_model, 'Weight', fig=fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d1c7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (16,9))\n",
    "sm.graphics.plot_regress_exog(Final_model, 'KM', fig=fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aec1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (16,9))\n",
    "sm.graphics.plot_regress_exog(Final_model, 'CC', fig=fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589f6074",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (16,9))\n",
    "sm.graphics.plot_regress_exog(Final_model, 'Doors', fig=fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcb2988",
   "metadata": {},
   "source": [
    "### ^Observation:\n",
    "\n",
    "* Some of the feature doesn't suggest linear relationship with the Dependent feature like Gears, QT, CC, Doors, Weight and HP\n",
    "* Only KM and Age is having a linear relation with the Price Feature\n",
    "\n",
    "### Predicting values from Model using same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c06d282",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataframe[['Age','KM','HP','CC','Doors','QT','Weight']]\n",
    "y = dataframe[['Price']]\n",
    "transformer_x = StandardScaler().fit(x)\n",
    "transformer_y = StandardScaler().fit(y)\n",
    "# Scale the test dataset\n",
    "x_train_scal = transformer_x.transform(x)\n",
    "y_train_scal = transformer_y.transform(y)\n",
    "\n",
    "# Linear Regression\n",
    "x_df = pd.DataFrame(x_train_scal, columns = ['Age','KM','HP','CC','Doors','QT','Weight'])\n",
    "x_df.head()\n",
    "\n",
    "# Predict with the trained model\n",
    "predict = pd.DataFrame(Final_model.predict(x_df))\n",
    "\n",
    "# Inverse transform the prediction\n",
    "predict_unscaled = transformer_y.inverse_transform(predict.values.reshape(-1,1))\n",
    "predict_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d3ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.sqrt(mean_squared_error(y, predict_unscaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e332db",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = pd.DataFrame(predict_unscaled,columns=['Predicted_Price'])\n",
    "predicted['Price'] = dataframe.Price\n",
    "predicted['Age'] = dataframe.Age\n",
    "predicted['KM'] = dataframe.KM\n",
    "predicted['Weight'] = dataframe.Weight\n",
    "predicted['HP'] = dataframe.HP\n",
    "predicted['CC'] = dataframe.CC\n",
    "predicted['QT'] = dataframe.QT\n",
    "predicted['Doors'] = dataframe.Doors\n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812536d1",
   "metadata": {},
   "source": [
    "### Preparing a table containing R2 value for each prepared model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c978c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models={'Different_Models':['Raw_data_Model','After_Removing_Influencers','After_Log Transformation_Model','After_Cube-root_Transformation_Model','After_Sqaure_Root_Transformation_Model','Final_Model_without_Multicollinearity_Model'],\n",
    "        'R_squared':[raw_data_model.rsquared,final_model.rsquared,log_transformed_model.rsquared,cbrt_transformed_model.rsquared,sqrt_transformed_model.rsquared,model_1.rsquared],\n",
    "        'R_squared_adjusted':[raw_data_model.rsquared_adj,final_model.rsquared_adj,log_transformed_model.rsquared_adj,cbrt_transformed_model.rsquared_adj,sqrt_transformed_model.rsquared_adj,model_1.rsquared_adj],\n",
    "       'RMSE':[np.sqrt(raw_data_model.mse_resid),np.sqrt(final_model.mse_resid),log_both_rmse,cube_root_both_rmse,square_root_both_rmse,rmse_linear]}\n",
    "model_table=pd.DataFrame(models)\n",
    "model_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ab48c5",
   "metadata": {},
   "source": [
    "### Visualizing Models Performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc42faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2,1, figsize=(14,10))\n",
    "\n",
    "model_table.sort_values(by=['R_squared'], ascending=False, inplace=True)\n",
    "\n",
    "sns.barplot(x='R_squared', y='Different_Models', data = model_table, palette='Blues_d', ax = axes[0])\n",
    "axes[0].set_xlabel('R_squared', size=16)\n",
    "axes[0].set_ylabel('Different_Models')\n",
    "axes[0].set_xlim(0,1.0)\n",
    "axes[0].set_xticks(np.arange(0, 1.1, 0.1))\n",
    "\n",
    "model_table.sort_values(by=['R_squared_adjusted'], ascending=False, inplace=True)\n",
    "\n",
    "sns.barplot(x='R_squared_adjusted', y='Different_Models', data = model_table, palette='Reds_d', ax = axes[1])\n",
    "axes[1].set_xlabel('R_squared_adjusted', size=16)\n",
    "axes[1].set_ylabel('Different_Models')\n",
    "axes[1].set_xlim(0,1.0)\n",
    "axes[1].set_xticks(np.arange(0, 1.1, 0.1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0859022d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_table.sort_values(by=['RMSE'], ascending=False, inplace=True)\n",
    "\n",
    "f, axe = plt.subplots(1,1, figsize=(22,12))\n",
    "sns.barplot(x='RMSE', y='Different_Models', data=model_table, ax = axe)\n",
    "axe.set_xlabel('Different_Models', size=20)\n",
    "axe.set_ylabel('RMSE', size=20)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "\n",
    "\n",
    "\n",
    "for i, v in enumerate(np.round(model_table.RMSE.values,0)):\n",
    "    axe.text(v + 3, i + .25, str(v),\n",
    "            color = 'black', fontweight = 'bold', fontsize= 16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829f8ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973c2cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression\n",
    "reg_model = LinearRegression().fit(x_train, y_train)\n",
    "print(reg_model.score(x_train, y_train),reg_model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc7a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gd_model = GradientBoostingRegressor(random_state=1).fit(x_train, y_train)\n",
    "print(gd_model.score(x_train, y_train),gd_model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ce7e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr_model = RandomForestRegressor(random_state=1).fit(x_train, y_train)\n",
    "print(rfr_model.score(x_train, y_train),rfr_model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ebb502",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Linear Regression Root Mean Squared Error:',np.sqrt(mean_squared_error(y_test, reg_model.predict(x_test))))\n",
    "print('Gradient Booster Regressor Root Mean Squared Error:',np.sqrt(mean_squared_error(y_test, gd_model.predict(x_test))))\n",
    "print('Random Forest Regressor Root Mean Squared Error:',np.sqrt(mean_squared_error(y_test, rfr_model.predict(x_test))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
